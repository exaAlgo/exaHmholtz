@kernel void scaledAdd(const exaUInt N,
                      const exaScalar alpha,
                      @restrict const exaScalar *x,
                      const exaScalar beta,
                      @restrict exaScalar *y)
{
  for(exaUInt n=0;n<N;n++;@tile(256,@outer,@inner)){
    if(n<N)
      y[n]=alpha*x[n]+beta*y[n];
  }
}

@kernel void weightedNorm2(const exaUInt N,
                           @restrict const exaScalar *w,
                           @restrict const exaScalar *x,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar wid=(id<N)?w[id]:0.0;
      s_out[t]=wid*xid*xid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}

#if 0
@kernel void innerProductTim(const exaUInt N,
			 @restrict const  exaScalar *  w,
			 @restrict const  exaScalar *  x,
			 @restrict exaScalar *  wx){


  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;++b;@outer(0)){

    @shared volatile exaScalar s_wx[p_blockSize];

    for(int t=0;t<p_blockSize;++t;@inner(0)){
      const exaUInt id = t + b*p_blockSize;
      s_wx[t] = (id<N) ? (w[id]*x[id]) : 0.f;
    }

    @barrier("local");

#if p_blockSize>512
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<512) s_wx[t] += s_wx[t+512];
    @barrier("local");
#endif

#if p_blockSize>256
    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<256) s_wx[t] += s_wx[t+256];
    @barrier("local");
#endif

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<128) s_wx[t] += s_wx[t+128];
    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 64) s_wx[t] += s_wx[t+ 64];
    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 32) s_wx[t] += s_wx[t+ 32];
    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t< 16) s_wx[t] += s_wx[t+ 16];
    //    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  8) s_wx[t] += s_wx[t+  8];
    //    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  4) s_wx[t] += s_wx[t+  4];
    //    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  2) s_wx[t] += s_wx[t+  2];
    //    @barrier("local");

    for(int t=0;t<p_blockSize;++t;@inner(0)) if(t<  1) wx[b] = s_wx[0] + s_wx[1];
  }
}
#endif

@kernel void innerProduct2(const exaUInt N,
                           @restrict const exaScalar *x,
                           @restrict const exaScalar *y,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar yid=(id<N)?y[id]:0.0;
      s_out[t]=xid*yid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}

@kernel void weightedInnerProduct2(const exaUInt N,
                           @restrict const exaScalar *w,
                           @restrict const exaScalar *x,
                           @restrict const exaScalar *y,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar yid=(id<N)?y[id]:0.0;
      const exaScalar wid=(id<N)?w[id]:0.0;
      s_out[t]=wid*xid*yid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}
