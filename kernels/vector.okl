@kernel void scaledAdd(const exaUInt N,
                      const exaScalar alpha,
                      @restrict const exaScalar *x,
                      const exaScalar beta,
                      @restrict exaScalar *y)
{
  for(exaUInt n=0;n<N;n++;@tile(256,@outer,@inner)){
    if(n<N)
      y[n]=alpha*x[n]+beta*y[n];
  }
}

@kernel void weightedNorm2(const exaUInt N,
                           @restrict const exaScalar *w,
                           @restrict const exaScalar *x,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar wid=(id<N)?w[id]:0.0;
      s_out[t]=wid*xid*xid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}

@kernel void innerProduct2(const exaUInt N,
                           @restrict const exaScalar *x,
                           @restrict const exaScalar *y,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar yid=(id<N)?y[id]:0.0;
      s_out[t]=xid*yid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}

@kernel void weightedInnerProduct2(const exaUInt N,
                           @restrict const exaScalar *w,
                           @restrict const exaScalar *x,
                           @restrict const exaScalar *y,
                           @restrict exaScalar *out)
{
  for(exaUInt b=0;b<(N+p_blockSize-1)/p_blockSize;b++;@outer(0)){
    @shared volatile exaScalar s_out[p_blockSize];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0)){
      const exaUInt id   =t+b*p_blockSize;
      const exaScalar xid=(id<N)?x[id]:0.0;
      const exaScalar yid=(id<N)?y[id]:0.0;
      const exaScalar wid=(id<N)?w[id]:0.0;
      s_out[t]=wid*xid*yid;
    }
    @barrier("local");

#if p_blockSize > 512
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<512) s_out[t]+=s_out[t+512];
    @barrier("local");
#endif
#if p_blockSize > 256
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<256) s_out[t]+=s_out[t+256];
    @barrier("local");
#endif
#if p_blockSize > 128
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<128) s_out[t]+=s_out[t+128];
    @barrier("local");
#endif
#if p_blockSize > 64
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<64) s_out[t]+=s_out[t+ 64];
    @barrier("local");
#endif

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<32) s_out[t]+=s_out[t+32];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<16) s_out[t]+=s_out[t+16];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 8) s_out[t]+=s_out[t+ 8];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 4) s_out[t]+=s_out[t+ 4];
    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t< 2) s_out[t]+=s_out[t+ 2];

    for(exaUInt t=0;t<p_blockSize;t++;@inner(0))
      if(t<1) out[b]=s_out[0]+s_out[1];
  }
}
